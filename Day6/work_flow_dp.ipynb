{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa2512ba9653e9b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:54:11.439550Z",
     "start_time": "2025-05-29T16:54:07.959747Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80670499358c548a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:54:11.452482Z",
     "start_time": "2025-05-29T16:54:11.447442Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create know parameters\n",
    "weights = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# create data\n",
    "start = 0\n",
    "end = 10\n",
    "step = 0.2\n",
    "\n",
    "x = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weights * x + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f8306fd38505c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:54:11.478184Z",
     "start_time": "2025-05-29T16:54:11.461102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.2000],\n",
       "         [0.4000],\n",
       "         [0.6000],\n",
       "         [0.8000],\n",
       "         [1.0000],\n",
       "         [1.2000],\n",
       "         [1.4000],\n",
       "         [1.6000],\n",
       "         [1.8000]]),\n",
       " tensor([[0.3000],\n",
       "         [0.4400],\n",
       "         [0.5800],\n",
       "         [0.7200],\n",
       "         [0.8600],\n",
       "         [1.0000],\n",
       "         [1.1400],\n",
       "         [1.2800],\n",
       "         [1.4200],\n",
       "         [1.5600]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b6464ae5e7e2c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:54:11.493048Z",
     "start_time": "2025-05-29T16:54:11.484371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split = int(0.8 * len(x))\n",
    "X_train, y_train = x[:train_split], x[:train_split]\n",
    "X_test, y_test = y[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de458fbca7690568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T16:54:11.530401Z",
     "start_time": "2025-05-29T16:54:11.526690Z"
    }
   },
   "outputs": [],
   "source": [
    "## Linear Regression from scratch\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.rand(1, requires_grad=True, dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.rand(1, requires_grad=True, dtype=torch.float))\n",
    "\n",
    "# Forward method to find the computation in the model\n",
    "    def forward (self, x):\n",
    "        return self.weights * x + self.bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22362764",
   "metadata": {},
   "source": [
    "# pytorch model building classes\n",
    "\n",
    "* torch.nn - contain all of the buildings for computational graphs(a another word for neural networks)\n",
    "* torch.nn parameter = what parameters  should our model try and learn, often a pytroch layer from torch.nn will set these for us\n",
    "* torch.nn.Module - the base class for all neuaral netwoks it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df0a2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.8823], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.9150], requires_grad=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random seed\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# create an instance of the model (this is a subclass of nn.Module)\n",
    "\n",
    "model= LinearRegressionModel()\n",
    "\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c841974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.8823])), ('bias', tensor([0.9150]))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffdd0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setub a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# setup an optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c22441",
   "metadata": {},
   "source": [
    "### building a training loop and testing loop\n",
    "* Loop through the data\n",
    "* forward pass - also called forward propagation\n",
    "* calculate the loss\n",
    "* optimizer zero grad\n",
    "* loss backward - calculate the gradient of each parameters **backpropagation**\n",
    "* optimzer step - **gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a80faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Test : 0.4560187757015228 | Test loss: 0.1223519816994667\n",
      "Epoch: 10 | Test : 0.3958054482936859 | Test loss: 0.051641084253787994\n",
      "Epoch: 20 | Test : 0.38337674736976624 | Test loss: 0.08508453518152237\n",
      "Epoch: 30 | Test : 0.37861353158950806 | Test loss: 0.11507654190063477\n",
      "Epoch: 40 | Test : 0.376332551240921 | Test loss: 0.1300235241651535\n",
      "Epoch: 50 | Test : 0.3740514814853668 | Test loss: 0.14497017860412598\n",
      "Epoch: 60 | Test : 0.37219512462615967 | Test loss: 0.14676980674266815\n",
      "Epoch: 70 | Test : 0.3704783022403717 | Test loss: 0.14669117331504822\n",
      "Epoch: 80 | Test : 0.3687562942504883 | Test loss: 0.14661264419555664\n",
      "Epoch: 90 | Test : 0.3670310378074646 | Test loss: 0.14465585350990295\n",
      "Epoch: 100 | Test : 0.3653142750263214 | Test loss: 0.1445775032043457\n",
      "Epoch: 110 | Test : 0.36359554529190063 | Test loss: 0.14449873566627502\n",
      "Epoch: 120 | Test : 0.3618670105934143 | Test loss: 0.14254216849803925\n",
      "Epoch: 130 | Test : 0.36015012860298157 | Test loss: 0.14246335625648499\n",
      "Epoch: 140 | Test : 0.358433336019516 | Test loss: 0.14238500595092773\n",
      "Epoch: 150 | Test : 0.35670289397239685 | Test loss: 0.14042797684669495\n",
      "Epoch: 160 | Test : 0.35498613119125366 | Test loss: 0.14034971594810486\n",
      "Epoch: 170 | Test : 0.3532692790031433 | Test loss: 0.14027079939842224\n",
      "Epoch: 180 | Test : 0.35153883695602417 | Test loss: 0.13831424713134766\n",
      "Epoch: 190 | Test : 0.34982213377952576 | Test loss: 0.13823576271533966\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "### training \n",
    "## 1.Loop through the data\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "\n",
    "    #calculate the loss\n",
    "    loss_value = loss_fn(y_pred, y_train)\n",
    " \n",
    "\n",
    "    # optimizer zer grad\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # performed backpropagation\n",
    "    loss_value.backward()\n",
    "\n",
    "    # step the optimzer\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    model.eval()     # turn off different settings in the model not needed for evaluating/testing\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # 1. do the forward\n",
    "        test_pred = model(X_test)\n",
    "\n",
    "        # 2. calculating the loss\n",
    "\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss_value)\n",
    "        test_loss_values.append(test_loss)\n",
    "        print(f\"Epoch: {epoch} | Test : {loss_value} | Test loss: {test_loss}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b1c9247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 10,\n",
       " 20,\n",
       " 30,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 70,\n",
       " 80,\n",
       " 90,\n",
       " 100,\n",
       " 110,\n",
       " 120,\n",
       " 130,\n",
       " 140,\n",
       " 150,\n",
       " 160,\n",
       " 170,\n",
       " 180,\n",
       " 190]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15f2e43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.4560, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3958, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3834, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3786, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3763, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3741, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3722, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3705, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3688, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3670, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3653, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3636, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3619, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3602, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3584, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3567, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3550, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3533, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3515, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3498, grad_fn=<MeanBackward0>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "971abcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.1224),\n",
       " tensor(0.0516),\n",
       " tensor(0.0851),\n",
       " tensor(0.1151),\n",
       " tensor(0.1300),\n",
       " tensor(0.1450),\n",
       " tensor(0.1468),\n",
       " tensor(0.1467),\n",
       " tensor(0.1466),\n",
       " tensor(0.1447),\n",
       " tensor(0.1446),\n",
       " tensor(0.1445),\n",
       " tensor(0.1425),\n",
       " tensor(0.1425),\n",
       " tensor(0.1424),\n",
       " tensor(0.1404),\n",
       " tensor(0.1403),\n",
       " tensor(0.1403),\n",
       " tensor(0.1383),\n",
       " tensor(0.1382)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c66d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1c5fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.8523])), ('bias', tensor([0.8260]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b4b2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.8523])), ('bias', tensor([0.8260]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9ec3424",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikram\\AppData\\Local\\Temp\\ipykernel_18728\\2771607331.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model1 = model.load_state_dict(torch.load('model_weights.pth'))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_IncompatibleKeys' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m model1\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_IncompatibleKeys' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "model1 = model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6080ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikram\\AppData\\Local\\Temp\\ipykernel_18728\\1968207754.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model_weights.pth'))  # Load the weights into it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionModel()  # Recreate the same model architecture\n",
    "model.load_state_dict(torch.load('model_weights.pth'))  # Load the weights into it\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
